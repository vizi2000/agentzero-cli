{"version": 2, "width": 100, "height": 32, "timestamp": 1737384000, "env": {"SHELL": "/bin/zsh", "TERM": "xterm-256color"}, "title": "Model Switching Demo"}
[0.0, "o", "\u001b[?1049h"]
[0.1, "o", "\u001b[1;1H\u001b[38;2;150;150;150m# Agent Zero CLI - Model Switching Demo\u001b[0m"]
[0.3, "o", "\r\n\u001b[38;2;150;150;150m# Your LM Studio is running at 192.168.3.1:1234\u001b[0m"]
[0.6, "o", "\r\n"]
[0.8, "o", "\r\n\u001b[38;2;200;200;200m$ \u001b[0m\u001b[38;2;100;200;255mexport LOCAL_LLM_URL=http://192.168.3.1:1234/v1\u001b[0m"]
[1.2, "o", "\r\n\u001b[38;2;200;200;200m$ \u001b[0m\u001b[38;2;100;200;255ma0\u001b[0m"]
[1.6, "o", "\r\n"]
[2.0, "o", "\r\n\u001b[38;2;100;200;255m[CONNECT]\u001b[0m Connecting to LM Studio..."]
[2.4, "o", "\r\n\u001b[38;2;100;200;255m[DETECT]\u001b[0m  Fetching available models from /v1/models..."]
[2.9, "o", "\r\n"]
[3.1, "o", "\r\n\u001b[38;2;255;200;100m┌──────────────────────────────────────────────────────────────────────────┐\u001b[0m"]
[3.2, "o", "\r\n\u001b[38;2;255;200;100m│\u001b[0m \u001b[1;38;2;255;200;100mAvailable Models on LM Studio (192.168.3.1:1234)\u001b[0m                        \u001b[38;2;255;200;100m│\u001b[0m"]
[3.3, "o", "\r\n\u001b[38;2;255;200;100m├──────────────────────────────────────────────────────────────────────────┤\u001b[0m"]
[3.5, "o", "\r\n\u001b[38;2;255;200;100m│\u001b[0m  \u001b[38;2;0;255;127m>\u001b[0m \u001b[1mmemagent-3b\u001b[0m                    \u001b[38;2;150;150;150m(auto-selected)\u001b[0m                     \u001b[38;2;255;200;100m│\u001b[0m"]
[3.7, "o", "\r\n\u001b[38;2;255;200;100m│\u001b[0m    liquid/lfm2.5-1.2b                                                    \u001b[38;2;255;200;100m│\u001b[0m"]
[3.9, "o", "\r\n\u001b[38;2;255;200;100m│\u001b[0m    mistralai/ministral-3-3b                                              \u001b[38;2;255;200;100m│\u001b[0m"]
[4.1, "o", "\r\n\u001b[38;2;255;200;100m│\u001b[0m    zai-org/glm-4.6v-flash                                                \u001b[38;2;255;200;100m│\u001b[0m"]
[4.3, "o", "\r\n\u001b[38;2;255;200;100m│\u001b[0m    text-embedding-nomic-embed-text-v1.5 \u001b[38;2;100;100;100m(embedding, skipped)\u001b[0m            \u001b[38;2;255;200;100m│\u001b[0m"]
[4.5, "o", "\r\n\u001b[38;2;255;200;100m└──────────────────────────────────────────────────────────────────────────┘\u001b[0m"]
[5.0, "o", "\r\n"]
[5.2, "o", "\r\n\u001b[38;2;0;255;127m[OK]\u001b[0m \u001b[1mLocal LLM connected - memagent-3b (SAFEST)\u001b[0m"]
[5.5, "o", "\r\n\u001b[38;2;150;150;150m     Data never leaves your network!\u001b[0m"]
[6.0, "o", "\r\n"]
[6.3, "o", "\r\n\u001b[38;2;150;150;150m# To use a specific model, set LOCAL_LLM_MODEL:\u001b[0m"]
[6.6, "o", "\r\n"]
[7.0, "o", "\r\n\u001b[38;2;200;200;200m$ \u001b[0m\u001b[38;2;100;200;255mexport LOCAL_LLM_MODEL=mistralai/ministral-3-3b\u001b[0m"]
[7.4, "o", "\r\n\u001b[38;2;200;200;200m$ \u001b[0m\u001b[38;2;100;200;255ma0\u001b[0m"]
[7.8, "o", "\r\n"]
[8.2, "o", "\r\n\u001b[38;2;100;200;255m[CONNECT]\u001b[0m Connecting to LM Studio..."]
[8.6, "o", "\r\n\u001b[38;2;100;200;255m[MODEL]\u001b[0m   Using specified model: mistralai/ministral-3-3b"]
[9.0, "o", "\r\n"]
[9.2, "o", "\r\n\u001b[38;2;0;255;127m[OK]\u001b[0m \u001b[1mLocal LLM connected - mistralai/ministral-3-3b (SAFEST)\u001b[0m"]
[9.6, "o", "\r\n"]
[10.0, "o", "\r\n\u001b[38;2;150;150;150m# You can also specify model inline:\u001b[0m"]
[10.4, "o", "\r\n"]
[10.8, "o", "\r\n\u001b[38;2;200;200;200m$ \u001b[0m\u001b[38;2;100;200;255mLOCAL_LLM_MODEL=liquid/lfm2.5-1.2b a0\u001b[0m"]
[11.2, "o", "\r\n"]
[11.5, "o", "\r\n\u001b[38;2;0;255;127m[OK]\u001b[0m \u001b[1mLocal LLM connected - liquid/lfm2.5-1.2b (SAFEST)\u001b[0m"]
[12.0, "o", "\r\n"]
[12.3, "o", "\r\n\u001b[38;2;255;200;100m─────────────────────────────────────────────────────────────────────────\u001b[0m"]
[12.5, "o", "\r\n\u001b[1;38;2;255;200;100m .env file example:\u001b[0m"]
[12.7, "o", "\r\n\u001b[38;2;255;200;100m─────────────────────────────────────────────────────────────────────────\u001b[0m"]
[13.0, "o", "\r\n"]
[13.2, "o", "\r\n\u001b[38;2;150;150;150m# .env\u001b[0m"]
[13.4, "o", "\r\n\u001b[38;2;100;200;255mLOCAL_LLM_URL\u001b[0m=http://192.168.3.1:1234/v1"]
[13.7, "o", "\r\n\u001b[38;2;100;200;255mLOCAL_LLM_MODEL\u001b[0m=mistralai/ministral-3-3b"]
[14.1, "o", "\r\n"]
[14.4, "o", "\r\n\u001b[38;2;150;150;150m# Or for Ollama:\u001b[0m"]
[14.6, "o", "\r\n\u001b[38;2;100;200;255mLOCAL_LLM_URL\u001b[0m=http://localhost:11434/v1"]
[14.9, "o", "\r\n\u001b[38;2;100;200;255mLOCAL_LLM_MODEL\u001b[0m=llama3.2:3b"]
[15.3, "o", "\r\n"]
[15.6, "o", "\r\n\u001b[38;2;255;200;100m─────────────────────────────────────────────────────────────────────────\u001b[0m"]
[16.0, "o", "\r\n"]
[16.2, "o", "\r\n\u001b[38;2;0;255;127mYour data stays on YOUR network. Always.\u001b[0m"]
[16.6, "o", "\r\n"]
[17.0, "o", "\u001b[?1049l"]
